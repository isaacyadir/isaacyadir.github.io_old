<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>python, statistics, bayes on Dr. Juan Camilo Orduz</title>
    <link>/tags/python-statistics-bayes/</link>
    <description>Recent content in python, statistics, bayes on Dr. Juan Camilo Orduz</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 04 Jan 2021 00:00:00 +0000</lastBuildDate><atom:link href="/tags/python-statistics-bayes/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>GLM in PyMC3: Out-Of-Sample Predictions</title>
      <link>/glm_pymc3/</link>
      <pubDate>Mon, 04 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>/glm_pymc3/</guid>
      <description>In this notebook I explore the glm module of PyMC3. I am particularly interested in the model definition using patsy formulas, as it makes the model evaluation loop faster (easier to include features and/or interactions). There are many good resources on this subject, but most of them evaluate the model in-sample. For many applications we require doing predictions on out-of-sample data. This experiment was motivated by the discussion of the thread “Out of sample” predictions with the GLM sub-module on the (great!</description>
    </item>
    
  </channel>
</rss>

<!DOCTYPE html>
<html lang="en-us">
  <head>
    <script defer src="https://use.fontawesome.com/releases/v5.13.0/js/all.js"></script>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.79.1" />


<title>PyData Berlin 2018: On Laplacian Eigenmaps for Dimensionality Reduction - Dr. Juan Camilo Orduz</title>
<meta property="og:title" content="PyData Berlin 2018: On Laplacian Eigenmaps for Dimensionality Reduction - Dr. Juan Camilo Orduz">


  <link href='../images/favicon.ico' rel='icon' type='image/x-icon'/>



  








<link href='//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/atom-one-light.min.css' rel='stylesheet' type='text/css' />



<link rel="stylesheet" href="../css/fonts.css" media="all">
<link rel="stylesheet" href="../css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="../" class="nav-logo">
    <img src="../images/sphere2.gif"
         width="50"
         height="50"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="../about/"> About</a></li>
    
    <li><a href="https://github.com/juanitorduz"><i class='fab fa-github fa-2x'></i>  </a></li>
    
    <li><a href="https://www.linkedin.com/in/juanitorduz/"><i class='fab fa-linkedin fa-2x' style='color:#0077B5;'></i>  </a></li>
    
    <li><a href="https://twitter.com/juanitorduz"><i class='fab fa-twitter fa-2x' style='color:#1DA1F2;'></i>  </a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    
    <span class="article-duration">6 min read</span>
    

    <h1 class="article-title">PyData Berlin 2018: On Laplacian Eigenmaps for Dimensionality Reduction</h1>

    
    <span class="article-date">2018-07-08</span>
    

    <div class="article-content">
      <p>This summer I had the great oportunity to attend an give a talk at <a href="https://pydata.org/berlin2018/">Pydata Berlin 2018</a>. The topic of my talk was <a href="https://pydata.org/berlin2018/schedule/presentation/33/">On Laplacian Eigenmaps for Dimensionality Reduction</a>. During the <em>Unsupervised Learning &amp; Visualization</em> session Dr. Stefan KÃ¼hn presented a very interesting and visual talk on <a href="https://pydata.org/berlin2018/schedule/presentation/55/">Manifold Learning and Dimensionality Reduction for Data Visualization and Feature Engineering</a> and Dr. Evelyn Trautmann gave a nice application of spectral clustering (<a href="http://www.kyb.mpg.de/fileadmin/user_upload/files/publications/attachments/Luxburg07_tutorial_4488%5b0%5d.pdf">here</a> are some nice notes around this subject) in the context of <a href="https://pydata.org/berlin2018/schedule/presentation/48/">Extracting relevant Metrics</a>. During our talks, spectral methods and the <a href="https://en.wikipedia.org/wiki/Laplacian_matrix">Graph Laplacian</a> was the biggest intersection. This was an excelent oportunity to enhance the communication channels between pure math and its applications.</p>
<p>I want to acknowledge the organizers, volunteers and great speakers which made this conference possible.</p>
<hr>
<p><strong>Abstract</strong></p>
<p>The aim of this talk is to describe a non-linear dimensionality reduction algorithm based on spectral techniques introduced in <a href="http://web.cse.ohio-state.edu/~belkin.8/papers/LEM_NC_03.pdf">BN2003</a>. The goal of non-linear dimensionality reduction algorithms, so called  <em>manifold learning algorithms</em>, is to construct a representation of data on a low dimensional manifold embedded in a high dimensional space. The particular case we are going to present exploits various relations of geometric and spectral methods (discrete and continuous). Spectral methods are sometimes motivated by Marc Kac&rsquo;s question  <em>Can One Hear the Shape of a Drum?</em> which makes reference to the idea of recovering geometrical properties from the eigenvalues (spectrum) of a matrix (linear operator). Concretely, the approach followed in <a href="http://web.cse.ohio-state.edu/~belkin.8/papers/LEM_NC_03.pdf">BN2003</a> has its foundation on the spectral analysis of the <a href="https://en.wikipedia.org/wiki/Laplacian_matrix">Graph Laplacian</a> of the adjacency graph constructed from the data. The motivation of the construction relies on the continuous limit analogue, the <a href="https://en.wikipedia.org/wiki/Laplace%E2%80%93Beltrami_operator">Laplace-Beltrami</a> operator, in providing an optimal embedding for manifolds. We will also indicate the relation with the associated heat kernel operator. Instead of following a pure formal approach we will present the main geometric and computational ideas of the algorithm. Hence, with basic knowledge of linear algebra (eigenvalues) and differential calculus you will be able to follow the talk. Finally we will show a concrete example in Python using <a href="http://scikit-learn.org/stable/modules/generated/sklearn.manifold.SpectralEmbedding.html">scikit-learn</a>.</p>
<hr>
<p><strong>Video</strong></p>
<!-- raw HTML omitted -->
<p><strong>Slides</strong></p>
<p><a href="../documents/orduz_pydata2018.pdf">Here</a> you can find the slides of the talk.</p>
<p>Suggestions and comments are always welcome!</p>
<hr>
<h2 id="jupyter-notebook">Jupyter Notebook</h2>
<p>In this notebook we present some simple examples which ilustrate the concepts discussed in the talk on <a href="https://pydata.org/berlin2018/schedule/presentation/33/">Laplacian Eigenmaps for Dimensionality Reduction</a> at <a href="https://pydata.org/berlin2018/">PyData Berlin 2018</a>.</p>
<p>The sample data, visualization code and object descriptions can be found in the documentation.</p>
<p><strong>References:</strong></p>
<ul>
<li>
<p><a href="http://scikit-learn.org/stable/modules/generated/sklearn.manifold.spectral_embedding.html">http://scikit-learn.org/stable/modules/generated/sklearn.manifold.spectral_embedding.html</a></p>
</li>
<li>
<p><a href="http://scikit-learn.org/stable/modules/manifold.html#spectral-embedding">http://scikit-learn.org/stable/modules/manifold.html#spectral-embedding</a></p>
</li>
</ul>
<h2 id="1-notebook-setup">1. Notebook Setup</h2>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#f92672">as</span> plt
<span style="color:#f92672">from</span> mpl_toolkits.mplot3d <span style="color:#f92672">import</span> Axes3D
<span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
<span style="color:#f92672">from</span> sklearn <span style="color:#f92672">import</span> manifold, datasets
<span style="color:#f92672">from</span> sklearn.utils <span style="color:#f92672">import</span> check_random_state
<span style="color:#f92672">from</span> sklearn.decomposition <span style="color:#f92672">import</span> PCA
</code></pre></div><h2 id="2-back-to-our-toy-example">2. Back to Our Toy Example</h2>
<!-- raw HTML omitted -->
<p>Let us compute the graph Laplacian from the adjacency matrix.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># Construct the adjacency matrix from the graph for n_neighbors = 1. </span>
W <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array([[<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>],
              [<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>], 
              [<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>], 
              [<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>]])

<span style="color:#75715e"># Construct the degree matrix D from W.</span>
D <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>diag(np<span style="color:#f92672">.</span>apply_along_axis(arr<span style="color:#f92672">=</span>W,
                                func1d<span style="color:#f92672">=</span>np<span style="color:#f92672">.</span>sum,
                                axis<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>))
<span style="color:#75715e"># Compute the graph Laplacian.</span>
L <span style="color:#f92672">=</span> D <span style="color:#f92672">-</span> W

<span style="color:#66d9ef">print</span>(L)
</code></pre></div><pre><code>[[ 3 -1 -1 -1]
 [-1  1  0  0]
 [-1  0  1  0]
 [-1  0  0  1]]
</code></pre>
<p>Let us use <code>manifold.spectral_embedding</code> to compute the projection onto \(\mathbb{R}\).</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">y <span style="color:#f92672">=</span> manifold<span style="color:#f92672">.</span>spectral_embedding(adjacency<span style="color:#f92672">=</span>W, 
                                n_components<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>, 
                                norm_laplacian<span style="color:#f92672">=</span>False, 
                                drop_first<span style="color:#f92672">=</span>True,
                                eigen_solver<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;lobpcg&#39;</span>)

<span style="color:#66d9ef">print</span>(y)
</code></pre></div><pre><code>[[ 0.        ]
 [-0.57735027]
 [ 0.78867513]
 [-0.21132487]]
</code></pre>
<p>Let us verify the result. Recall that the first non zero eigenvalue of is \(\lambda_1 = 1\).</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">lambda_1 <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>

<span style="color:#75715e"># Check if the previous output coincides with the analytical requirement. </span>
np<span style="color:#f92672">.</span>array_equal(a1<span style="color:#f92672">=</span>np<span style="color:#f92672">.</span>dot(L, y), 
               a2<span style="color:#f92672">=</span>lambda_1<span style="color:#f92672">*</span>np<span style="color:#f92672">.</span>dot(D, y))
</code></pre></div><pre><code>True
</code></pre>
<p>Thus, \(y\) is a solution of \(Lf = \lambda_1 Df\) with \(\lambda_1 =1\).</p>
<h2 id="3-higher-dimensional-examples">3 Higher Dimensional Examples</h2>
<h3 id="31-s-curve">3.1 S Curve</h3>
<p><strong>Reference:</strong> <a href="http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_s_curve.html">http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_s_curve.html</a></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># Define the number of points to consider. </span>
n_points <span style="color:#f92672">=</span> <span style="color:#ae81ff">3000</span>

<span style="color:#75715e"># Get the data and color map. </span>
S_curve, S_colors <span style="color:#f92672">=</span> datasets<span style="color:#f92672">.</span>samples_generator<span style="color:#f92672">.</span>make_s_curve(n_points, random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)

Axes3D

fig <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>figure(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">12</span>, <span style="color:#ae81ff">12</span>))
ax <span style="color:#f92672">=</span> fig<span style="color:#f92672">.</span>add_subplot(<span style="color:#ae81ff">111</span>, projection<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;3d&#39;</span>)
ax<span style="color:#f92672">.</span>scatter(S_curve[:, <span style="color:#ae81ff">0</span>], S_curve[:, <span style="color:#ae81ff">1</span>], S_curve[:, <span style="color:#ae81ff">2</span>],
           c<span style="color:#f92672">=</span>S_colors, 
           cmap<span style="color:#f92672">=</span>plt<span style="color:#f92672">.</span>cm<span style="color:#f92672">.</span>Spectral)
ax<span style="color:#f92672">.</span>view_init(<span style="color:#ae81ff">4</span>, <span style="color:#f92672">-</span><span style="color:#ae81ff">72</span>);
</code></pre></div><!-- raw HTML omitted -->
<h4 id="311-pca">3.1.1 PCA</h4>
<p>Let us see the result of PCA with <code>n_components=2</code>.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># Fit PCA object.</span>
S_curve_pca <span style="color:#f92672">=</span> PCA(n_components<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>)<span style="color:#f92672">.</span>fit_transform(S_curve)

<span style="color:#75715e"># Visualize the result.</span>
fig <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>figure(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">12</span>, <span style="color:#ae81ff">6</span>))
ax <span style="color:#f92672">=</span> fig<span style="color:#f92672">.</span>add_subplot(<span style="color:#ae81ff">111</span>)
ax<span style="color:#f92672">.</span>scatter(S_curve_pca[:, <span style="color:#ae81ff">0</span>], S_curve_pca[:, <span style="color:#ae81ff">1</span>],
           c<span style="color:#f92672">=</span>S_colors, 
           cmap<span style="color:#f92672">=</span>plt<span style="color:#f92672">.</span>cm<span style="color:#f92672">.</span>Spectral);
</code></pre></div><!-- raw HTML omitted -->
<p>The result is coincides with ouur intuition, it is basically projecting to an axis so that the variance is maximized.</p>
<h4 id="312-spectral-embedding">3.1.2 Spectral Embedding</h4>
<p>Now let us use the method <code>SpectralEmbedding</code> from <code>sklearn</code>.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># Set the number of n_neighbors;</span>
n_neighbors <span style="color:#f92672">=</span> <span style="color:#ae81ff">6</span> 

<span style="color:#75715e"># Set the dimension of the target space. </span>
n_components <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span>

<span style="color:#75715e"># Construct the SpectralEmbedding object. </span>
se <span style="color:#f92672">=</span> manifold<span style="color:#f92672">.</span>SpectralEmbedding(n_components<span style="color:#f92672">=</span>n_components,
                                affinity<span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;nearest_neighbors&#39;</span>,
                                n_neighbors<span style="color:#f92672">=</span>n_neighbors)

<span style="color:#75715e"># Fit the SpectralEmbedding object. </span>
S_curve_red <span style="color:#f92672">=</span> se<span style="color:#f92672">.</span>fit_transform(X<span style="color:#f92672">=</span>S_curve)

<span style="color:#75715e"># Visualize the result.</span>
fig <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>figure(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">12</span>, <span style="color:#ae81ff">6</span>))
ax <span style="color:#f92672">=</span> fig<span style="color:#f92672">.</span>add_subplot(<span style="color:#ae81ff">111</span>)
ax<span style="color:#f92672">.</span>scatter(S_curve_red[:, <span style="color:#ae81ff">0</span>], S_curve_red[:, <span style="color:#ae81ff">1</span>],
           c<span style="color:#f92672">=</span>S_colors, 
           cmap<span style="color:#f92672">=</span>plt<span style="color:#f92672">.</span>cm<span style="color:#f92672">.</span>Spectral);
</code></pre></div><!-- raw HTML omitted -->
<p>We see that <code>SpectralEmbedding</code> <em>unroll</em> the S-curve so that the locallity is preserved on average.</p>
<p>Now let us consider <code>n_neighbors</code> &raquo; 1.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># Set the number of n_neighbors;</span>
n_neighbors <span style="color:#f92672">=</span> <span style="color:#ae81ff">1500</span> 

<span style="color:#75715e"># Set the dimension of the target space. </span>
n_components <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span>

<span style="color:#75715e"># Construct the SpectralEmbedding object. </span>
se <span style="color:#f92672">=</span> manifold<span style="color:#f92672">.</span>SpectralEmbedding(n_components<span style="color:#f92672">=</span>n_components,
                                affinity<span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;nearest_neighbors&#39;</span>,
                                n_neighbors<span style="color:#f92672">=</span>n_neighbors)

<span style="color:#75715e"># Fit the SpectralEmbedding object. </span>
S_curve_red <span style="color:#f92672">=</span> se<span style="color:#f92672">.</span>fit_transform(X<span style="color:#f92672">=</span>S_curve)

<span style="color:#75715e"># Visualize the result.</span>
fig <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>figure(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">12</span>, <span style="color:#ae81ff">6</span>))
ax <span style="color:#f92672">=</span> fig<span style="color:#f92672">.</span>add_subplot(<span style="color:#ae81ff">111</span>)
ax<span style="color:#f92672">.</span>scatter(S_curve_red[:, <span style="color:#ae81ff">0</span>], S_curve_red[:, <span style="color:#ae81ff">1</span>],
           c<span style="color:#f92672">=</span>S_colors, 
           cmap<span style="color:#f92672">=</span>plt<span style="color:#f92672">.</span>cm<span style="color:#f92672">.</span>Spectral);
</code></pre></div><!-- raw HTML omitted -->
<p>The result is that the problem becomes more <em>global</em>. Thus, we get a similar result as PCA.</p>
<h3 id="32-two-dimensional-sphere-s2">3.2 Two Dimensional Sphere \(S^2\)</h3>
<p><strong>Reference:</strong> <a href="http://scikit-learn.org/stable/auto_examples/manifold/plot_manifold_sphere.html">http://scikit-learn.org/stable/auto_examples/manifold/plot_manifold_sphere.html</a></p>
<p>First we generate the data.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># Create our sphere.</span>
n_samples <span style="color:#f92672">=</span> <span style="color:#ae81ff">5000</span>

angle_parameter <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.5</span> <span style="color:#75715e"># Try 0.01</span>
pole_hole_parameter <span style="color:#f92672">=</span> <span style="color:#ae81ff">8</span> <span style="color:#75715e"># Try 50</span>

random_state <span style="color:#f92672">=</span> check_random_state(<span style="color:#ae81ff">0</span>)
p <span style="color:#f92672">=</span> random_state<span style="color:#f92672">.</span>rand(n_samples) <span style="color:#f92672">*</span> (<span style="color:#ae81ff">2</span> <span style="color:#f92672">*</span> np<span style="color:#f92672">.</span>pi <span style="color:#f92672">-</span> angle_parameter)
t <span style="color:#f92672">=</span> random_state<span style="color:#f92672">.</span>rand(n_samples) <span style="color:#f92672">*</span> np<span style="color:#f92672">.</span>pi

<span style="color:#75715e"># Sever the poles from the sphere.</span>
indices <span style="color:#f92672">=</span> ((t <span style="color:#f92672">&lt;</span> (np<span style="color:#f92672">.</span>pi <span style="color:#f92672">-</span> (np<span style="color:#f92672">.</span>pi <span style="color:#f92672">/</span> pole_hole_parameter))) <span style="color:#f92672">&amp;</span> 
           (t <span style="color:#f92672">&gt;</span> ((np<span style="color:#f92672">.</span>pi <span style="color:#f92672">/</span> pole_hole_parameter))))
colors <span style="color:#f92672">=</span> p[indices]
x, y, z <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>sin(t[indices]) <span style="color:#f92672">*</span> np<span style="color:#f92672">.</span>cos(p[indices]), \
          np<span style="color:#f92672">.</span>sin(t[indices]) <span style="color:#f92672">*</span> np<span style="color:#f92672">.</span>sin(p[indices]), \
          np<span style="color:#f92672">.</span>cos(t[indices])
        
sphere_data <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array([x, y, z])<span style="color:#f92672">.</span>T
</code></pre></div><p>Let us visualize the data.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">fig <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>figure(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">12</span>, <span style="color:#ae81ff">12</span>))
ax <span style="color:#f92672">=</span> fig<span style="color:#f92672">.</span>add_subplot(<span style="color:#ae81ff">111</span>, projection<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;3d&#39;</span>)
ax<span style="color:#f92672">.</span>scatter(x, y, z,
           c<span style="color:#f92672">=</span>colors, 
           cmap<span style="color:#f92672">=</span>plt<span style="color:#f92672">.</span>cm<span style="color:#f92672">.</span>Spectral);
</code></pre></div><!-- raw HTML omitted -->
<h4 id="321-pca">3.2.1 PCA</h4>
<p>Again, let us begin using PCA.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">sphere_pca <span style="color:#f92672">=</span> PCA(n_components<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>)<span style="color:#f92672">.</span>fit_transform(sphere_data)

fig <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>figure(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">10</span>))
ax <span style="color:#f92672">=</span> fig<span style="color:#f92672">.</span>add_subplot(<span style="color:#ae81ff">111</span>)
ax<span style="color:#f92672">.</span>scatter(sphere_pca[:, <span style="color:#ae81ff">0</span>], sphere_pca[:, <span style="color:#ae81ff">1</span>],
           c<span style="color:#f92672">=</span>colors, 
           cmap<span style="color:#f92672">=</span>plt<span style="color:#f92672">.</span>cm<span style="color:#f92672">.</span>Spectral);
</code></pre></div><!-- raw HTML omitted -->
<h4 id="332-spectral-embedding">3.3.2 Spectral Embedding</h4>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">n_neighbors <span style="color:#f92672">=</span> <span style="color:#ae81ff">8</span>
n_components <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span>

<span style="color:#75715e"># Fit the object.</span>
se <span style="color:#f92672">=</span> manifold<span style="color:#f92672">.</span>SpectralEmbedding(n_components<span style="color:#f92672">=</span>n_components,
                                affinity<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;nearest_neighbors&#39;</span>,
                                n_neighbors<span style="color:#f92672">=</span>n_neighbors)

sphere_data_red <span style="color:#f92672">=</span> se<span style="color:#f92672">.</span>fit_transform(X<span style="color:#f92672">=</span>sphere_data)
</code></pre></div><p>Let us visualize the results.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">fig <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>figure(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">10</span>))
ax <span style="color:#f92672">=</span> fig<span style="color:#f92672">.</span>add_subplot(<span style="color:#ae81ff">111</span>)
ax<span style="color:#f92672">.</span>scatter(sphere_data_red[:, <span style="color:#ae81ff">0</span>], sphere_data_red[:, <span style="color:#ae81ff">1</span>],
           c<span style="color:#f92672">=</span>colors, 
           cmap<span style="color:#f92672">=</span>plt<span style="color:#f92672">.</span>cm<span style="color:#f92672">.</span>Spectral);
</code></pre></div><!-- raw HTML omitted -->
<p>We see how <code>SpectralEmbedding</code> unrolls the sphere.</p>
<p>Finally, let us take again <code>n_neighbors</code> &raquo; 1.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">n_neighbors <span style="color:#f92672">=</span> <span style="color:#ae81ff">1000</span>

<span style="color:#75715e"># Fit the object.</span>
se <span style="color:#f92672">=</span> manifold<span style="color:#f92672">.</span>SpectralEmbedding(n_components<span style="color:#f92672">=</span>n_components,
                                affinity<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;nearest_neighbors&#39;</span>,
                                n_neighbors<span style="color:#f92672">=</span>n_neighbors)

sphere_data_red <span style="color:#f92672">=</span> se<span style="color:#f92672">.</span>fit_transform(X<span style="color:#f92672">=</span>sphere_data)

fig <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>figure(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">10</span>))
ax <span style="color:#f92672">=</span> fig<span style="color:#f92672">.</span>add_subplot(<span style="color:#ae81ff">111</span>)
ax<span style="color:#f92672">.</span>scatter(sphere_data_red[:, <span style="color:#ae81ff">0</span>], sphere_data_red[:, <span style="color:#ae81ff">1</span>],
           c<span style="color:#f92672">=</span>colors, 
           cmap<span style="color:#f92672">=</span>plt<span style="color:#f92672">.</span>cm<span style="color:#f92672">.</span>Spectral);
</code></pre></div><!-- raw HTML omitted -->

    </div>
  </article>

  


</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="../index.xml" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>
          <li>
            <a href="https://gohugo.io/" class="footer-links-kudos">Made with <img src="../images/hugo-logo.png" alt="Img link to Hugo website" width="22" height="22"></a>
          </li>
        </ul>
      </footer>

    </div>
    



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/r.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/yaml.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/python.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/dockerfile.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/bash.min.js"></script>
<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>



    
<script src="../js/math-code.js"></script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-122570825-1', 'auto');
	
	ga('send', 'pageview');
}
</script>

  </body>
</html>

